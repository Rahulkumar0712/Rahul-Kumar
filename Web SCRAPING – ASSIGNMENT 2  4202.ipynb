{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1ed729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0be0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/jobs-in-delhi-ncr?roleTypeFilterGid=169&ctcFilter=3to6&clusters=roleGid,salaryRange'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b3a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings = soup.find_all('article', class_='jobtitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182e1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212c3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in job_listings[:10]:\n",
    "    title = listing.find('a', class_='title').text.strip()\n",
    "    job_titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = listing.find('li', class_=\"locWdth\").text.strip()\n",
    "job_locations.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c174a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = listing.find('a', class_=\" comp-name mw-25\").text.strip()\n",
    "company_names.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = listing.find('li', class_=\"2-7 Yrs \").text.strip()\n",
    "experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36c0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Job Title': job_titles,\n",
    "                   'Job Location': job_locations,\n",
    "                   'Company Name': company_names,\n",
    "                   'Experience Required': experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb45e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Job Title, Job Location, Company Name, Experience Required]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df3d3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "268a5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.shine.com/job-search/data-scientist-jobs-in-bangalore?q=data-scientist&loc=Bangalore'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2477458",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings = soup.find_all('li', class_='s-resultListItem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7dfc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "job_locations = []\n",
    "company_names = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36535c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in job_listings[:10]:\n",
    "    title = listing.find('h2', class_='s-title').text.strip()\n",
    "    job_titles.append(title)\n",
    "    location = listing.find('span', class_=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\").text.strip()\n",
    "    job_locations.append(location)\n",
    "    company = listing.find('a', class_='ALIKE THOUGHTS SOLUTIONS PRIVATE LIMITED').text.strip()\n",
    "    company_names.append(company)\n",
    "    experience = listing.find('span', class_=\"JobDetailWidget_jobCard_lists_item__w6Yow JobDetailWidget_jobIcon__mjaNB undefined\").text.strip()\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cee0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Job Title': job_titles,\n",
    "                   'Job Location': job_locations,\n",
    "                   'Company Name': company_names,\n",
    "                   'Experience Required': experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e907f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Job Title, Job Location, Company Name, Experience Required]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31890c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e53c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_containers = soup.find_all('div', class_='_2d4LTz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b50951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "review_summaries = []\n",
    "full_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2fc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in review_containers[:100]:\n",
    "    rating = review.find('div', class_='_2d4LTz').text.strip()\n",
    "    ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc65ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = review.find('p', class_='_2-N8zT').text.strip()\n",
    "review_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_review = review.find('div', class_='t-ZTKy').text.strip()\n",
    "full_reviews.append(full_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffecb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(\"Review\", i+1)\n",
    "    print(\"Rating:\", ratings[i])\n",
    "    print(\"Review Summary:\", review_summaries[i])\n",
    "    print(\"Full Review:\", full_reviews[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888719b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Rating, Review Summary, Full Review]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Rating': ratings, 'Review Summary': review_summaries, 'Full Review': full_reviews})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef43177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ade0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/search?q=sneakers'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee044eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sneaker_containers = soup.find_all('div', class_='_2kHMtA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c51bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = []\n",
    "descriptions = []\n",
    "prices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9096a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sneaker in sneaker_containers[:100]:\n",
    "    brand = sneaker.find('div', class_='_2WkVRV').text.strip()\n",
    "    brands.append(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99202eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = sneaker.find('a', class_='IRpwTa').text.strip()\n",
    "descriptions.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cacc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = sneaker.find('div', class_='_30jeq3').text.strip()\n",
    "prices.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(\"Sneaker\", i+1)\n",
    "    print(\"Brand:\", brands[i])\n",
    "    print(\"Description:\", descriptions[i])\n",
    "    print(\"Price:\", prices[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e67ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Brand, Description, Price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Brand': brands, 'Description': descriptions, 'Price': prices})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8aea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ca9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field = driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "search_field.send_keys(\"Laptop\")\n",
    "search_field.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"s-result-list\")))\n",
    "cpu_filter = driver.find_element(By.XPATH, \"//span[contains(text(),'Intel Core i7')]\")\n",
    "cpu_filter.click()\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"s-result-list\")))\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e367632c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page_source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m laptop_listings \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms-result-item\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m listing \u001b[38;5;129;01min\u001b[39;00m laptop_listings[:\u001b[38;5;241m10\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'page_source' is not defined"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "laptop_listings = soup.find_all('div', class_='s-result-item')\n",
    "for listing in laptop_listings[:10]:\n",
    "    title = listing.find('span', class_='a-size-large product-title-word-break').text.strip()\n",
    "    ratings = listing.find('span', class_='a-icon a-icon-star a-star-4-5 cm-cr-review-stars-spacing-big').text.strip()\n",
    "    price = listing.find('span', class_='a-price-whole').text.strip()\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Ratings:\", ratings)\n",
    "    print(\"Price:\", price)\n",
    "    print(\"-\" * 50)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97a342f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215d9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bad7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "588a8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes_link = driver.find_element(By.XPATH, \"//a[contains(text(),'Top Quotes')]\")\n",
    "top_quotes_link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"list\")))\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_items = soup.find_all('div', class_='wrap-block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote_item in quote_items[:1000]:\n",
    "    quote_text = quote_item.find('a', class_='title').text.strip()\n",
    "    author = quote_item.find('span', class_='author').text.strip()\n",
    "    type_of_quote = quote_item.find('span', class_='kw-box').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0380d77",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2333617878.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Author:\", author)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "print(\"Quote:\", quote_text)\n",
    "    print(\"Author:\", author)\n",
    "    print(\"Type of Quote:\", type_of_quote)\n",
    "    print(\"-\" * 50)\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb72ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e8fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.jagranjosh.com/general-knowledge/list-of-all-prime-ministers-of-india-1473165149-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d91bfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cdd0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a66b100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', class_='table')\n",
    "rows = table.find_all('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "born_dead = []\n",
    "term_of_office = []\n",
    "remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    names.append(cols[0].text.strip())\n",
    "    born_dead.append(cols[1].text.strip())\n",
    "    term_of_office.append(cols[2].text.strip())\n",
    "    remarks.append(cols[3].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad18853d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: names,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBorn-Dead\u001b[39m\u001b[38;5;124m'\u001b[39m: born_dead,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerm of Office\u001b[39m\u001b[38;5;124m'\u001b[39m: term_of_office,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemarks\u001b[39m\u001b[38;5;124m'\u001b[39m: remarks})\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Born-Dead': born_dead,\n",
    "    'Term of Office': term_of_office,\n",
    "    'Remarks': remarks})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dfd84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78fb8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH, \"//input[@id='header-search']\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")\n",
    "search_bar.send_keys(Keys.RETURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f337622",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, \"//h2[contains(text(),'50 Most Expensive Cars in the World')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beccd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"listing-item\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297648a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_listings = soup.find_all('div', class_='listing-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb032421",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_names = []\n",
    "car_prices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b26a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for car in car_listings:\n",
    "    car_name = car.find('h3', class_='title').text.strip()\n",
    "    car_price = car.find('span', class_='price').text.strip()\n",
    "    car_names.append(car_name)\n",
    "    car_prices.append(car_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Car Name': car_names,\n",
    "    'Price': car_prices\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30164dd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m      2\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9b74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
